# embodied ai

| **Title** | **Abstract** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[DANLI: Deliberative Agent for Following Natural Language Instructions](http://arxiv.org/abs/2210.12485v1)** | <details><summary>Show</summary><p>Recent years have seen an increasing amount of work on embodied AI agents that can perform tasks by following human language instructions. However, most of these agents are reactive, meaning that they simply learn and imitate behaviors encountered in the training data. These reactive agents are insufficient for long-horizon complex tasks. To address this limitation, we propose a neuro-symbolic deliberative agent that, while following language instructions, proactively applies reasoning and planning based on its neural and symbolic representations acquired from past experience (e.g., natural language and egocentric vision). We show that our deliberative agent achieves greater than 70% improvement over reactive baselines on the challenging TEACh benchmark. Moreover, the underlying reasoning and planning processes, together with our modular framework, offer impressive transparency and explainability to the behaviors of the agent. This enables an in-depth understanding of the agent's capabilities, which shed light on challenges and opportunities for future embodied agents for instruction following. The code is available at https://github.com/sled-group/DANLI.</p></details> | 2022-10-22 | <details><summary>Accep...</summary><p>Accepted in EMNLP 2022</p></details> |
| **[Diversity-aware social robots meet people: beyond context-aware embodied AI](http://arxiv.org/abs/2207.05372v2)** | <details><summary>Show</summary><p>The article introduces the concept of "diversity-aware" robotics and discusses the need to develop computational models to embed robots with diversity-awareness: that is, robots capable of adapting and re-configuring their behavior to recognize, respect, and value the uniqueness of the person they interact with to promote inclusion regardless of their age, race, gender, cognitive or physical capabilities, etc. Finally, the article discusses possible technical solutions based on Ontologies and Bayesian Networks, starting from previous experience with culturally competent robots.</p></details> | 2022-10-10 | <details><summary>The a...</summary><p>The article has been presented during the Roundtable "AI in holistic care and healing practices: the caring encounter beyond COVID-19", Anthropology, AI and the Future of Human Society, 6-10 June 2022, Royal Anthropological Institute</p></details> |
| **[Embodied Referring Expression for Manipulation Question Answering in Interactive Environment](http://arxiv.org/abs/2210.02709v1)** | <details><summary>Show</summary><p>Embodied agents are expected to perform more complicated tasks in an interactive environment, with the progress of Embodied AI in recent years. Existing embodied tasks including Embodied Referring Expression (ERE) and other QA-form tasks mainly focuses on interaction in term of linguistic instruction. Therefore, enabling the agent to manipulate objects in the environment for exploration actively has become a challenging problem for the community. To solve this problem, We introduce a new embodied task: Remote Embodied Manipulation Question Answering (REMQA) to combine ERE with manipulation tasks. In the REMQA task, the agent needs to navigate to a remote position and perform manipulation with the target object to answer the question. We build a benchmark dataset for the REMQA task in the AI2-THOR simulator. To this end, a framework with 3D semantic reconstruction and modular network paradigms is proposed. The evaluation of the proposed framework on the REMQA dataset is presented to validate its effectiveness.</p></details> | 2022-10-06 |  |